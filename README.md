# Автоматизация выгрузки и загрузки чеков торговой сети

## Описание проекта

Этот проект автоматизирует процесс сбора и загрузки данных о продажах для крупной торговой сети товаров для дома (бытовая химия, текстиль, посуда и др.).  
Каждый день из кассовых программ генерируются выгрузки по чекам, которые затем загружаются в единую базу данных PostgreSQL для аналитики.

---

## Состав проекта

- **config.ini** — параметры генерации, категории товаров, диапазоны цен, параметры БД
- **sales_data.py** — генератор тестовых чеков (CSV)
- **run.py** — основной скрипт: запускает генерацию и загрузку в БД
- **pgdb.py** — работа с PostgreSQL
- **sql/create_tables.sql** — SQL-скрипт создания таблицы sales1
- **requirements.txt** — зависимости Python
- **.gitignore** — игнорируемые файлы/папки
- **data/** — папка для выгрузок чеков (csv по каждой кассе)
- **img/** — скриншоты автоматизации и структуры БД
- **logs/** — логи (по желанию)
- **example.csv** — пример структуры csv-выгрузки
- **README.md** — эта инструкция

---

## Быстрый старт

### 1. Клонирование и установка зависимостей

```bash
git clone <ССЫЛКА_НА_РЕПОЗИТОРИЙ>
cd <ИМЯ_ПРОЕКТА>
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

### 2. Настройка базы данных
Создайте базу данных PostgreSQL (например, sales).
Выполните скрипт из sql/create_tables.sql:
CREATE TABLE IF NOT EXISTS sales1 (
    doc_id VARCHAR(32) NOT NULL,
    item VARCHAR(255) NOT NULL,
    category VARCHAR(100),
    amount INT,
    price INT,
    discount INT,
    PRIMARY KEY (doc_id, item)
);

### 3. Настройка config.ini и переменных окружения
Укажите параметры подключения к БД (host, port, имя базы).
Перед запуском укажите переменные окружения:
export DB_USER=имя_пользователя
export DB_PASSWORD=пароль_пользователя
export DB_NAME=имя_бд

## Запуск
Для ручной генерации и загрузки данных выполните:
python run.py

Старые файлы из data/ удаляются автоматически при запуске.
Обрабатываются только .csv-файлы, лишние игнорируются.

## Проверка

Откройте БД в pgAdmin или DBeaver и выполните:
SELECT * FROM sales1 LIMIT 10;
В репозитории есть пример файла: example.csv.

## Автоматизация через cron (Linux/Mac)

Откройте редактор cron:
crontab -e
Добавьте строку (ежедневно 8:00, кроме воскресенья):
0 8 * * 1-6 /полный/путь/к/venv/bin/python /полный/путь/к/run.py >> /полный/путь/к/logs/cron.log 2>&1
Все логи работы автоматизации пишутся в файл logs/cron.log.
Скриншот вывода команды crontab -l добавьте в img/cron_example.png.

## Архитектурные решения

Для каждой кассы формируется отдельный .csv (shopnum_cashnum.csv).
doc_id уникален по всей сети (формат shop_cash_id).
Для надёжной уникальности чеков в столбце `doc_id` используется формат:  
`shopnum_cashnum_randomid` (например, 3_2_4821), что исключает дублирование чеков даже при одновременной генерации файлов для разных магазинов и касс.  
Старые выгрузки автоматически удаляются, загружаются только новые.
В папке data/ обрабатываются только .csv, лишние файлы игнорируются.
Гибкая настройка параметров генерации через config.ini.
Масштабируемость: новые категории, магазины, диапазоны цен легко добавлять в config.ini.
Логи работы автоматизации — файл logs/cron.log (создаётся при первом запуске cron).
Папка logs/ не коммитится в git (см. .gitignore).
Обработка ошибок: при ошибках генерации или загрузки скрипты выводят сообщения в консоль и в лог-файл (cron.log).
## FAQ

Что делать, если данные не загружаются?

Проверьте содержимое logs/cron.log.
Проверьте параметры подключения в config.ini и переменные окружения.
Как изменить количество магазинов, касс, категорий?

Измените значения в config.ini и перезапустите скрипт.
Как проверить, что автоматизация работает?

Убедитесь, что в logs/cron.log появляются новые записи после времени запуска по cron.
Проверьте появление новых файлов в data/ и новых записей в таблице sales1.


